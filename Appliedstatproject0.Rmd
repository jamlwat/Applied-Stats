---
title: "Applied Stats Module 0 Project- 2024 GAC Softball Hitting Statistics"
author: "Jami Watson"
date: "2025-02-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
df<-read.csv("https://raw.githubusercontent.com/nurfnick/Data_Sets_For_Stats/refs/heads/master/CuratedDataSets/24GAChittingstatsUpdate.csv", fileEncoding = "UTF-8")

head(df)
```

```{r}
head(df)
```
I found this data at https://static.greatamericanconference.com/custompages/SOFTBALL%20Stats/2024/lgplyrs.htm. For this project we will be focusing on the quantitative variables RBIs, games played (GP), and games started (GS), and the categorical variables team and starters (GP/GS).
```{r}
summary(df)
```
Summary statistics of quantitative variable RBI's
```{r}
summary(df$RBI)
```
Standard Deviation of RBI's
```{r}
sd(df$RBI, na.rm = TRUE)
```
```{r}
hist(df$RBI, 
     main = "Histogram of RBI", 
     xlab = "RBI", 
     ylab = "Frequency", 
     col = "blue", 
     border = "black")
```

```{r}
boxplot(df$RBI, 
        main = "Box Plot of RBI", 
        ylab = "Values", 
        col = "lightblue", 
        border = "black", 
        horizontal = FALSE)
```
```{r}
qqnorm(df$RBI, main = "QQ Plot of RBI")
qqline(df$RBI, col = "red", lwd = 2)  # Adds a reference line
```

From the above graphical displays, I found that there were multiple outliers within the data and the distribution was heavily skewed. This is most likely due to the data including all players in the GAC, including starters, non-starters, and non-hitters.

Frequency and relative frequency tables for categorical variable, Teams. These values should closely align with roster count of each team in the GAC in the 2024 season.
```{r}
freq_table <- table(df$Team)
print(freq_table)
```
```{r}
rel_freq_table <- prop.table(freq_table)
print(rel_freq_table)
```
Two way table comparing games played and games started to determine number of starters on each team. A player is considered a starter if they start in 75% of games played. To be clear, this does not guarantee all starters are hitters, but it narrows down our data.
```{r}
df$Starters<-df$GS/df$GP>0.75
```
```{r}
table(df$Team,df$Starters)
```
Null Hypothesis- True mean is equivalent to 15 RBIs

Alternative Hypothesis- True mean is not equivalent to 15 RBIs
```{r}
t.test(df$RBI,mu=15)
```
We received a low p-value so we reject the null hypothesis. The true mean of RBIs among all players is not 15. 

Null Hypothesis- True mean among starters is equivalent to 15 RBIs

Alternative Hypothesis- True mean among starters is not equivalent to 15 RBIs
```{r}
t.test(df[df$Starters,"RBI"],mu=15)
```
We received a low p-value so we reject the null hypothesis. The true mean of RBIs among starters is not 15. However, I must say my estimate was very close to the true mean.

Null Hypothesis- True difference in means of RBIs of starters and non-starters is 0

Alternative Hypothesis- True difference in means of RBIs of starters and non-starters is not 0
```{r}
t.test(df[df$Starters,"RBI"],df[!df$Starters,"RBI"])
```
We received a low p-value so we reject the null hypothesis. The true difference in means of RBIs of starters and non-starters is not 0.


In conclusion, there is a significant difference in the mean number of RBIs of starters and non-starters, which accounts for why our initial data distribution of RBIs among players was so skewed. The mean number of RBIs among starters was not 15, however, I was very close with my estimate as the true mean was 15.929688. I suppose next I will remove non-hitters from my data set and see what results I get then.

```{r}


plot(df$Hits, df$AVG, 
     main = "Scatter Plot", 
     xlab = "Hits", 
     ylab = "AVG", 
     col = "blue", 
     pch = 19)

model <- lm(AVG ~ Hits, data = df)


abline(model, col = "red", lwd = 2)


```


```{r}
intercept <- coef(model)[1]
slope <- coef(model)[2]

eq <- paste0("y = ", round(intercept, 5), " + ", round(slope, 5), "x")
print(eq)
```

```{r}
cor(df$Hits, df$AVG)
cor.test(df$Hits, df$AVG)
```
While this does show a positive relationship between hits and batting average, it is not a very strong relationship. Lets look at and compare the correlations between and hits and batting average of starters and non starters.
```{r}
ggplot(data = df, aes(x = Hits,y = AVG, colour = Starters))+
  geom_jitter()+
  geom_smooth(method = 'lm')

```
We can clearly see that among starters, the relationship between hits and batting average is strong. However, among non starters the relationship is very weak, as we would expect.
```{r}
predict(model,df[df$Player == "Watson",],interval="confidence")

model$residuals[43]

```
Players actual average was 0.297 which is within our interval.
```{r}
predict(model,data.frame(Hits = c(50)))
```
Based on our regression, a player with 50 hits would have a 0.352 batting average.
```{r}
plot(model)
```

```{r}
summary(model)
```
```{r}
lm(AVG~.-Player-SB.ATT,df)
```

```{r}
aggregate(HBP ~ Team, data = df, FUN = sum)
```
Total HBP of each team in the GAC

We will now perform a bootstrap mean on RBIs and compare this to our mean we computed early on in Module 0. Original Hypothesis test:
Null Hypothesis- True mean is equivalent to 15 RBIs
Alternative Hypothesis- True mean is not equivalent to 15 RBIs
```{r}
library(boot)
boot_mean <- function(df, indices) {
  return(mean(df[indices]))
}
set.seed(123)
bootstrap_results <- boot(df$RBI, boot_mean, R = 1001)
print(bootstrap_results)
```
Our original mean was 9.232 and the difference between our original mean and our bootstrap mean is 0.02373.This means our bootstrap mean is 9.255 RBIs.
```{r}
hist(bootstrap_results$t, breaks = 30, main = "Bootstrap Means RBI", xlab = "Mean Value", col = "lightblue", border = "black")
```

```{r}
boot.ci(bootstrap_results, type = c("perc", "bca"))
```
The 95% confidence interval for the mean is approximately between 7.989 and 10.663 RBIs.Since our null hypothesis of 15 RBI's does not lie within our interval, we can reject the null hypothesis.

For my new hypothesis test:
Null hypothesis- True mean is equivalent to 20 BB's (walks).
Alternative hypothesis- True mean is not equivalent to 20 BB's (walks).
```{r}
library(boot)
boot_mean <- function(df, indices) {
  return(mean(df[indices]))
}
set.seed(123)
bootstrap_results <- boot(df$BB, boot_mean, R = 1001)
print(bootstrap_results)
```
My estimate was obviously pretty far off, I think if we could run the bootstrap mean on starters only it would have been more on target.
```{r}
hist(bootstrap_results$t, breaks = 30, main = "Bootstrap Means BB's", xlab = "Mean Value", col = "lightblue", border = "black")
```
Looking at the distribution, I renounce my previous statement, 20 walks was a heavy overestimate...
```{r}
boot.ci(bootstrap_results, type = c("perc", "bca"))
```
My mean estimate is no where near the confidence interval here, thus we reject the null hypothesis. True mean is not equivalent to 20 BB's.

Onto Cross validation
```{r}
library(caret)
trainingsample <- createDataPartition(df$Hits, p=0.667,list=FALSE)
```
Randomly selected 2/3 of the data to be my training data.
```{r}
traindata <- df[trainingsample, ]
testdata <- df[-trainingsample, ]
```
Assigned this training data to traindata, and assigned the rest, the remaining 1/3, to be testdata.
```{r}
model <- lm(AVG ~ Hits, data = traindata)
summary(model)
```
Created a linear model of our train data. Our r squared isn't great, which makes sense because our original r squared wasn't great.
```{r}
plot(traindata$Hits,traindata$AVG,col="red")
points(testdata$Hits,testdata$AVG,col="blue")
abline(model)
```
Plotted our traindata (red) and testdata (blue) in a scatter plot along with our linear model.
```{r}
pre <- predict(model, testdata)
```
```{r}
R2(pre, testdata$AVG)
```
Examined our predication on our test data.
```{r}
train.control <- trainControl(method="cv", number=10)
model <- train(AVG~Hits, 
               data=df,
               method='lm',
               trControl=train.control)
print(model)
```
Performed a 10-fold cross validation. Tbh idk what exactly this is telling me....
